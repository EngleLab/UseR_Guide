# Example: Data Preparation

```{r echo=FALSE}
knitr::include_graphics(rep("images/workflow.png"))
```

Chapters 5 through 7 should have provided you all you need to know in order to start writing scripts to get your data ready for statistical analysis. The data preparation steps include **1)** converting "messy" raw data to "tidy" raw data and **2)** creating data file with task scores that have gone through data cleaning.

Based on the information from Chapters 5 through 7. **This Chapter** will go over step-by-step how to create R scripts to do data preparation using an example data set from the Flanker task. 

You can download this example data set here 

[Download Example Flanker Data](http://englelab.gatech.edu/R/example_data/Flanker_Example.zip)

********

## Initial Setup

### Set up directory structure

First let's setup our directory organization. In the directory where your .Rproj file is located, you should create the following folders:

* __R Scripts__ - A folder to put all your scripts in one place

* __Data Files__ - A folder where any data files will be stored

* __Results__ - A folder where any outputed results and figures will be stored

When conducting a study you might have other directores such as "Tasks" where the task files are located, or "Methods" where any methods documents or materials are located.

The **Results** directory will become relevant later when we get into performing statistical analyses on data.

Within the **Data Files** directory you should create the following folders:

* __Raw Data__ - A folder containing raw data files

* __Scored Data__ - A folder containig scored data files

Within the **Raw Data** folder you should create the following directory

* __E-Merge__ - A folder containing E-Merged and exported .txt merged files

This structure helps to keep clear where we are importing and outputing data files to in the data workflow process.

* The "messy" raw data files are located in the **E-Merge** folder.

* The "tidy" raw data files are located in the **Raw Data** folder.

* The scored task files are located in the **Scored Data** folder.

Our R Scripts should be able to completely (100%) recreate ALL files in the **Raw Data** and **Scored Data** files based on what is in the **E-Merge** folder. 

Unzip the Example Flanker data to the **E-Merge** folder.

One of the files is an E-Merged file, the other is the E-Merged file exported to a tab-delimited .txt file. There is also a folder labled **subj**. 

We will come back to what these files are later.

## Masterscript

In Chapter 7, you saw an example masterscript. Lets' go over how to begin creating one.

First open a new script window **File -> New File -> R Script**

Save the script as "masterscript_RTutorial.R" to where your .Rproj file is located (the home directory).

Alternatively you might prefer to save the script as "0_masterscript_RTutorial.R" in the **R Scripts** folder. The reason for the 0 will become evident later.

At the top of every script I like to have a "Setup" section where I load packages, set import and output directories, and set any other important variables.

In the masterscript I like to create a list object that contains the directory structure we created above. And then save that directory tree as an R object (.rds) to the home directory. 

What this allows is for each script that we are going to create to access the same directory tree by importing the directory tree R object file (.rds). It will not be apparent to you now, but this will save a lot of time when you have many R scripts. 

For instance: If the folder names have changed, you will not have to update the file paths in each R script, rather you can just do it from the masterscript. Also, if you want to copy and paste the same scripts to use in a different study (that used the same tasks) then, again, you do not have to update each R script to reflect the different folder names for that study. You can just update the masterscript.

This allows you to foucs on writing and executing the scripts rather than wasting time on getting the file path names perfect across every script.

```{r collapse=TRUE, message=FALSE}
## Setup ####
library(here)

## Set the directory tree
directories <- list(scripts = "R Scripts",
                    data = "Data Files",
                    raw = "Data Files/Raw Data",
                    messy = "Data Files/Raw Data/E-Merge",
                    scored = "Data Files/Scored Data",
                    results = "Results")

saveRDS(directories, here("directories.rds"))
#############
```

Now if we want to access the **E-Merge** folder path in an R Script we could do so by

```{r collapse=TRUE}
directories <- readRDS(here("directories.rds"))

directories$messy
```

For now we are done with the masterscript. We will come back later and add lines of code to run the scripts you will create in these examples.

Go ahead and source the masterscript to create the directories object file.

********

<br><br>

********

## Creating "messy" Merged File

Before performing the data preparation procedures, you will need to create a "messy" raw data file that is a merge of the individual subject files. 

* If the data files were created with E-Prime 2.0 you HAVE to do this using the E-Merge software program. 

* If the data files were created with E-Prime 3.0 AND the option to export as .txt is enabled, then you have to choice to by-pass the E-Merge software program and perform the merge in R instead,

### E-Prime 2.0

Individual subject data files created from tasks in E-Prime 2.0, HAVE to be merged together by

1. Creatingt an E-Merged file using the E-Merge software. 

2. Exporting that E-Merged file to a .txt file. 

I've already done these two steps for you. 

### Skipping E-Merge with E-Prime 3.0

Altenratively, in E-Prime 3.0 we have the option to skip over these two steps completely. In E-Prime 3.0 there is the option to output a .txt version of the .edat file that is created when a subject finishes a task. This means we will be able to directly import the individual subject data files into R without going through E-Prime software. 

The **subj** folder, in the zip folder you downloaded, contains individual subject .edat files exported as a .txt file. We will cover how to merge these individual files into one Merged file.

Create a new script and save it as "._study_finish.txt" in the **R Scripts** folder. The purpose of this script is to get to a single Merged file for all subject. This is a step that is typically only done once or as few times as possible. Because of this will not put it into the masterscript and we do not assign the script name a number (use "." in place).

First create the setup section at the top of the script. We will need the following packages; `here`, `datawrangling`, and `readr`.

```{r message=FALSE, warning=FALSE}
## Setup ####
library(here)
library(datawrangling)
library(readr)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- paste(directories$messy, "subj", sep = "/")
output.dir <- directories$messy

## Set import and output file names
output.file <- "Flanker.txt"
#############
```

We will use the `files_bind()` function from the `datawrangling` package to stack each subject file ontop of one another.

```{r collapse = TRUE, message = FALSE, warning = FALSE, eval = FALSE}
## Merge data files
files_bind(path = here(import.dir), pattern = "Flanker", output.file = here(output.dir, output.file))
```

This should do it. So your entire script should look something like

```{r message=FALSE, warning=FALSE, collapse = TRUE, eval = FALSE}
## Setup ####
library(here)
library(datawrangling)
library(readr)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- paste(directories$messy, "subj", sep = "/")
output.dir <- directories$messy
#############

## Merge data files
files_bind(path = here(import.dir), pattern = "Flanker", output.file = here(output.dir, output.file))

rm(list=ls())
```

Source and save your script.

********

<br><br>

********

## Step 1: "messy" to "tidy"

The first step in the data preparation procedure is to creat a "tidy" raw data file from the "messy" raw data file.

### What to Include

Creating a "tidy" raw data file is essentialy a process of elimination. Getting rid of columns and rows that have no value. You may also want to rename columns and values.

**So what should you keep?** 

You want to keep all **columns** that are essential to the design of the task. This might include a column that specifies the condition for each trial, a column that specifies a feature of the target stimulus, performance variables, and more. 

As for **rows**, I suggest keeping both practice and real trials. It is easy to filter out practice trials later. The "tidy" raw data file should contain only one row per trial per subject. 

You should probably **rename variables and values** to be easy for those unfamiliar with how the task was programmed to understand. Also if you have similar tasks (_Flanker_ and _Stroop_) it is probably a good idea to give similar names to variables and values. For instance, give the same name to the column that contains the condition type. Also use the same value names for each condition (not _congruent_ for one task, and _cong_ for another). Use a standard name for columns with reaction time and accuracy values (RT, Accuracy).

### Import "messy" data

Open a new script file and save it to the **R Scripts** folder as "1_flanker_raw"

The "1" denotes that this is the first step in our workflow process; converting "messy" raw data files to "tidy" raw data files.

Again, create the setup section at the top

```{r message = FALSE, warning = FALSE}
## Setup ####
library(here)
library(readr)
library(dplyr)
library(datawrangling)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- directories$messy
output.dir <- directories$raw

## Set import and output file names
import.file <- "Flanker.txt"
output.file <- "Flanker_raw.txt"
#############
```

Okay, first thing is to import the "messy" merged .txt data file. To do this use the `read_delim` function from the `readr` package. 

```{r collapse=TRUE, warning=FALSE, message=FALSE}
## Import
import <- read_delim(here(import.dir, import.file), "\t", escape_double = FALSE, trim_ws = TRUE)
```

You can then view the data file with

```{r eval=FALSE}
View(import)
```

It is a mess, right? Here are some things you need to know about the "messy" raw data file. These are the columns and what type of values they contain:

********

**Subject**: Subject number

**Procedure[Trial]**: Procedure type (keep: TrialProc and PracTrialProc)

**PracTrialList.Sample**: Trial number for practice trials

**TrialList.Sample**: Trial number for real trials

**FlankerType**: condition for real and practice trials (Values are: congruent, incongruent, and neutral)

**PracSlideTarget.RT**: Reaction time for practice trials

**PracSlideTarget.ACC**: Accuracy for practice trials

**PracSlideTarget.RESP**: Response for practice trials ({LEFTARROW} = left and {RIGHTARROW} = right)

**SlideTarget.RT**: Reaction time for real trials

**SlideTarget.ACC**: Accuracy for real trials

**SlideTarget.RESP**: Response for real trials ({LEFTARROW} = left and {RIGHTARROW} = right)

**TargerDirection**: direction of the target arrow for practice trials

**TargetDirection**: direction of the target arrow for real trials

**SessionDate**: Date of session

**SessionTime**: Time of session

********

### Remove Duplicate Subjects

Now it happens on occasion that the wrong subject number is entered in when an RA is starting up a task. This can result in duplicate Subject numbers in the E-Merge file. Luckily I have created a function to remove the duplicate subjects, and put their information (with session date and time) into a specific file. This file will be created in a new folder called "duplicates".

The function is `duplicates_remove()` from the `datawrangling` package on my GitHub.

It can be difficult to remember what arguments you need to include in a function. To see helpful documentation about a function you can type in the console

```{r eval=FALSE}
library(datawrangling)
?duplicates_remove
```


```{r warning=FALSE, collapse=TRUE, message=FALSE}
## Import
import <- read_delim(here(import.dir, import.file), "\t", escape_double = FALSE, trim_ws = TRUE)
import <- duplicates_remove(import, taskname = "Flanker", output.folder = here(output.dir))
```

### Filter Rows

Filter only relevant rows. We want to keep only the rows that contain trials from the practice and real trials. To do this we use the `filter()` function of the `dplyr` package. 

```{r warning=FALSE, collapse=TRUE, message=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc")
```

The column names are contained in single quotes because the names contain the special characters `[ ]`. There are certain characters R does not like to use as variable names and one of them is square brackets.

### Rename Variables

Now the column specifying real vs practice trials is a little tedious to keep typing out since it requires the single quotes and brackets. We will also want to rename this column to be more coherent in the final "tidy" data format anyways. To rename columns we can use `rename()` function in `dplyr`.

```{r warning=FALSE, collapse=TRUE, message=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`)
```

### Rename Values

Let's change the values in `TrialProc`. Right now real trials have the value of "TrialProc". The same name as the column, not good! And the "practice" trials have the value of "PractTrialProc". Let's simply change these values to "real" and "practice", respectively. 

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = ifelse(TrialProc=="TrialProc", "real", "practice"))
```

Note that we are not being very specific with `ifelse()`. Rows that do not equal `"TrialProc"` get set as `"practice"`. This is okay ONLY because we already applied a filter to only include rows with the value `"TrialProc"` or with the value `"PracTrialProc"`. If we did not apply this filter, or if there were more than two values for the column `TrialProc`, then rows that were not `"PracTrialProc"` would get set to `"practice"` as well. 

The point is, be careful how you are using `ifelse()`.

An alternative to `ifelse()` that I like is the `case_when()` function from `dplyr`. You can be more specific with `case_when()`. 
```{r collapse = TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)))
```

In `case_when()` you still specify a logical argument `TrialProc=="TrialProc"` and you set what should happen when that argument is TRUE by using the `~` symbol. So, cases when `TrialProc=="TrialProc"` set `~` value to `"real"`. At the End of `case_when()` you need to specify what should happen if none of those cases specified above are TRUE. You do this by typing `TRUE ~ ` followed by what to do. Usually you will want to set the value to missing. The tricky thing here is that `NA` is a logical value. A column of values can only be of one type (e.g. a column cannot contain both logical and character values). To get around this we just set `NA` to whatever value the column should take `as.character(NA)`.

********

Okay now let's move on to figuring out what other columns we want to keep and if we need to do any more computations on them.

We want to keep the columns that specify the following information

* Subject number
* TrialProc (real vs practice)
* Trial number 
* Condition (congruent vs incongruent)
* Reaction time
* Accuracy
* Response
* Target arrow direction (left or right)
* Session Date
* Session Time

This gets a little more tricky here because the information for some of these variables are in one column for practice trials and a different column for real trials. That means we need to merge the information from these two columns into one. We can do this using the`mutate()` function from the `dplyr` package.

For instance the RT data for practice trials is contained in the column `PracSlideTarget.RT` and for real trials RT data is in `SlideTarget.RT`.

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT))
```

So the new column RT gets set to the value that is contained in SlideTarget.RT if it is a real trial, if not then the RT gets a value contained in PracSlideTarget.RT

We can do the same thing for trial, accuracy, response, and target arrow direction. Combining them all into one `mutate()` function

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT),
         Accuracy = ifelse(TrialProc=="real", SlideTarget.ACC, PracSlideTarget.ACC),
         TargetArrowDirection = ifelse(TrialProc=="real", TargetDirection, TargerDirection),
         Response = ifelse(TrialProc=="real", SlideTarget.RESP, PracSlideTarget.RESP))
```

You might want to change the values in the Response and CorrectResponse columns to be more clear (left and right).

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT),
         Accuracy = ifelse(TrialProc=="real", SlideTarget.ACC, PracSlideTarget.ACC),
         TargetArrowDirection = ifelse(TrialProc=="real", TargetDirection, TargerDirection),
         Response = ifelse(TrialProc=="real", SlideTarget.RESP, PracSlideTarget.RESP),
         Response = ifelse(Response=="{LEFTARROW}", "left", ifelse(Response=="{RIGHTARROW}", "right", NA)))
```

Notice how I included an `ifelse()` function inside of an `ifelse()` function. The inner `ifelse()` will occur if `Response` does not equal `"{LEFTARROW}"`. This is another way to be more specific when using `ifelse()` instead of `case_when()`. It is up to you which you prefer to use.

You have to be careful with `ifelse()` statements because sometimes it does something you do not expect it to. **That is why it is always important to check to make sure your code is performing as you want it to.** View the dataframe to make sure everything is good. The new columns will be added at the end of the dataframe.

### Select Columns

We are getting closer to a "tidy" raw data file. The only thing left is to select the columns we want to keep. We do this by using the `select()` function from the `dplyr` package.

Remember we want to only select columns with the following information

* Subject number
* Trial number 
* Condition
* Reaction time
* Accuracy
* Response
* Correct Response
* Target arrow direction
* Session Date
* Session Time

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT),
         Accuracy = ifelse(TrialProc=="real", SlideTarget.ACC, PracSlideTarget.ACC),
         TargetArrowDirection = ifelse(TrialProc=="real", TargetDirection, TargerDirection),
         Response = ifelse(TrialProc=="real", SlideTarget.RESP, PracSlideTarget.RESP),
         Response = ifelse(Response=="{LEFTARROW}", "left", ifelse(Response=="{RIGHTARROW}", "right", NA))) %>%
  select(Subject, TrialProc, Trial, Condition = FlankerType, RT, Accuracy, Response, TargetArrowDirection, SessionDate, SessionTime)
```

### Save to File

The function of an R script is to import a dataframe -> transform or analyze the dataframe -> output a final product (a new dataframe or analysis output). The objects which an R script creates (which you can see in the **Environemnt** window) are not the final end point. These are just temporary objects that are used to go from an input -> output. 

You have done the importing and transforming; now you need to output the final product - which is a saved .txt file of the "tidy" raw data.

To save the dataframe to a .txt file you will use the `write_delim()` function of the `readr` package.

```{r collapse=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
## Save
write_delim(data_flanker, path = here(output.dir, output.file), delim = "\t", na = "")
```

********

Then if we were to put it all together, using the template from the previous chapter:

```{r message = FALSE, warning = FALSE, collapse=TRUE}
## Setup ####
library(here)
library(readr)
library(dplyr)
library(datawrangling)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- directories$messy
output.dir <- directories$raw

## Set import and output file names
import.file <- "Flanker.txt"
output.file <- "Flanker_raw.txt"
#############

## Import
import <- read_delim(here(import.dir, import.file), "\t", escape_double = FALSE, trim_ws = TRUE) %>%
  duplicates_remove(taskname = "Flanker", output.folder = here(output.dir))

## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT),
         Accuracy = ifelse(TrialProc=="real", SlideTarget.ACC, PracSlideTarget.ACC),
         TargetArrowDirection = ifelse(TrialProc=="real", TargetDirection, TargerDirection),
         Response = ifelse(TrialProc=="real", SlideTarget.RESP, PracSlideTarget.RESP),
         Response = ifelse(Response=="{LEFTARROW}", "left", ifelse(Response=="{RIGHTARROW}", "right", NA))) %>%
  select(Subject, TrialProc, Trial, Condition = FlankerType, RT, Accuracy, Response, TargetArrowDirection, SessionDate, SessionTime)

## Save
write_delim(data_flanker, path = here(output.dir, output.file), delim = "\t", na = "")

rm(list=ls())
```

Great! You have written an R script for the first step in Data Preparation, converting a "messy" raw data file to a "tidy" raw data file. 

********

<br>

********

## Step 2: raw "tidy" to scored

Next we will go over how to write an R script for the second step - which involves **data cleaning and task scoring**.

This step is more complicated and often times requires some forethought. But we don't always have the best forethought so you will likely re-write previous lines of code.

One thing you must think about before writing the script for this stage is the statistical analyses you eventually plan on conducting. This is because the final resulting dataframe will depend on what analyses you do. The data structure required for conducting a between-subject mean comparison will be different from the data structure required for a within-subject mean comparison or regression. The type of statistical analyses you plan on conducting will determine the final dataframe you want to end up at in this stage of data preparation.

Another thing you must think about before hand are the final dependent variables (or task scores) you want to calaculate. For instance, in the Flanker task there are several task scores we might want to calculate (in a regression context). 

* __FlankerEffect on RT__: Mean reaction time difference between incongruent and congruent trials

* __FlankerEffect on Accuracy__: Mean accuracy difference between incongruent and congruent trials

* __Flanker Binned Scores__: A scoring method to combine accuracy and reaction time (an alternative to difference scores)

Finally, you should also think about what sort of data cleaning procedures you want to use. For instance, maybe you only want to calculate the FlankerEffect on RT for accurate trials and not innaccurate trials. Or perhaps you want to remove trials that are less than 200ms (too fast of responding to reflect cognitive processing).

********

First start by opening a new script file and saving it to the **R Scripts** folder as "2_flanker_score"

### Set up

Create the Setup section of the R script. In addition to the import and output directories we will set the data cleaning paramters as well.

```{r}
## Setup ####
library(here)
library(readr)
library(dplyr)
library(datawrangling)
library(englelab)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- directories$raw
output.dir <- directories$scored

## Set import and output files
import.file <- "Flanker_raw.txt"
output.file <- "Flanker_Scores.txt"
#############
```

Import directory is the **Raw Data** folder where the "tidy" raw file is located. The output directory is the **Scored Data** folder.

### Import

```{r message = FALSE}
## Import ####
import <- read_delim(here(import.dir, import.file), "\t", escape_double = FALSE, trim_ws = TRUE)
##############
```

### Data Cleaning

In the example we are about to go through we will implement the following data cleaning procedures when calculating the three scores listed above. They will be implemented in the following order

1. Set RTs less than 200ms to missing (`NA`)

2. Trim RTs. Replace Outlier RTs that are above or below **3.5 SDs** of the mean, with values exactly at **3.5 SDs** above or below the mean. This is evaluated for each Subject by each condition seprately.

3. Finally remove subjects that on any Trial condition (congruent, incongruent, neutral) performed less than **3.5 standard deviations** below the mean on that condition.

First we need to get rid of **practice trials** / keep only **real trials**.

```{r}
## Trim RTs ####
data_trim <- import %>%
  filter(TrialProc == "real")
#################
```

Then, 

1. set RTs less than 200ms to missing (`NA`) using `mutate()`

```{r}
## Trim RTs ####
data_trim <- import %>%
  filter(TrialProc == "real") %>%
  mutate(RT = ifelse(RT < 200, NA, RT))
#################
```

And,

2. Trim RTs, grouped by **Subject** and **Condition** using the `trim()` function from the `datawrangling` package.

```{r}
## Trim RTs ####
data_trim <- import %>%
  filter(TrialProc == "real") %>%
  mutate(RT = ifelse(RT < 200, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = 3.5, replace = "cutoff") %>%
  ungroup()
#################
```

**Always be sure to `ungroup()` aftewards.**

Note the `replace` argument in `trim()`. Outliers are being replaced with the value at 3.5 SDs of the mean (the cutoff value). Outliers can also be replaced with the `"mean"`, `"median"`, or `"NA"`.

We will implement the third data cleaning procedure later.

### Calculate FlankerEffect on RT and Accuracy

The general strategy we will take is to create two different dataframes. 1) `data_flanker` in which we calculate the FlankerEffect on RT and Accuracy and 2) `data_binned` in which we calculate the Flanker Binned scores. Then we will merge the two dataframes together.

#### Calculate Mean RTs and Mean Accuracy

We will want to calculate the Flanker Effect on RT for accurate trials only. So let's set RTs on innacurate trials to `NA`.

```{r}
## Calculate FlankerEffect on RT and Accuracy ####
data_flanker <- data_trim %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT))
##################################################
```

Now we can calculate mean RTs and Accuracy for each condition per subject using `group_by()` and `summarise()`

```{r}
## Calculate FlankerEffect on RT and Accuracy ####
data_flanker <- data_trim %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  summarise(RT.mean = mean(RT, na.rm = TRUE),
            Accuracy.mean = mean(Accuracy, na.rm = TRUE)) %>%
  ungroup()
##################################################
```

Be sure to `ungroup()` when you are done with it!

And then spread "RT" and "Accuracy" across conditions. Creating columns for mean RT and mean Accuracy for each separate condition.

```{r}
## Calculate FlankerEffect on RT and Accuracy ####
data_flanker <- data_trim %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  summarise(RT.mean = mean(RT, na.rm = TRUE),
            Accuracy.mean = mean(Accuracy, na.rm = TRUE)) %>%
  ungroup() %>%
  reshape_spread(variables = "Condition", values = c("RT.mean", "Accuracy.mean"), id = "Subject")
##################################################
```

Now the dataframe is setup to calculate Flanker Effects.

```{r}
## Calculate FlankerEffect on RT and Accuracy ####
data_flanker <- data_trim %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  summarise(RT.mean = mean(RT, na.rm = TRUE),
            Accuracy.mean = mean(Accuracy, na.rm = TRUE)) %>%
  ungroup() %>%
  reshape_spread(variables = "Condition", values = c("RT.mean", "Accuracy.mean"), id = "Subject") %>%
  mutate(FlankerEffect_RT = incongruent_RT.mean - congruent_RT.mean,
         FlankerEffect_ACC = incongruent_Accuracy.mean - congruent_Accuracy.mean)
##################################################
```

### Remove Subjects

The approach I like to take with entirely removing subjects is to keep a record of those subjects in a data file somewhere. To do this we will 1) create a new dataframe of subjects that will be removed and then 2) use a function I created, `remove_save()` from the `datawrangling` package. This function is a short hand way of doing two things at once. 

1. Removing the subjects from the full data file

2. Saving the removed subjects to a specified directory.

The criteria we are removing subjects based on are those who performed 3.5 SDs below the mean. So we first need to calaculate a column of z-scores (on SD units), then filter those who are below 3.5 z-scores.

```{r}
## Remove poor performing subjects ####
data_remove <- data_flanker %>%
  center(variables = c("congruent_Accuracy.mean", 
                       "incongruent_Accuracy.mean", 
                       "neutral_Accuracy.mean"), 
         standardize = TRUE) %>%
  filter(congruent_Accuracy.mean_z < (-3.5) |
           incongruent_Accuracy.mean_z < (-3.5) | 
           neutral_Accuracy.mean_z < (-3.5))
```

Then use `remove_save()`

```{r}
data_flanker <- remove_save(data_flanker, data_remove, 
                            output.dir = here(output.dir, "removed"), 
                            output.file = "Flanker_removed.txt")
#######################################
```

The first argument is the full data frame (`data_flanker`) and the second argument is the dataframe that contains the subjects to be removed (`data_remove`). You should now see a folder called **removed** in the **Scored Data** folder with a file called "Flanker_removed.txt".

### Calculate Binned Scores

Great! We have now calculated FlankerEffects scores and perfomred the data cleaning procedures. Now we need to calculate Binned scores. The `data_flanker` dataframe is no longer in a formate that we can calculate bin scores. We need to the trimmed dataframe that has trial level data. 

We should remove the poor performing subjects and Missing RTs. **This step is actually really important for the binning procedure because bin scores are relative to other subjects in the data.**

```{r}
## Calculate Binned scores ####
data_binned <- data_trim %>%
  filter(!is.na(RT), !(Subject %in% data_remove$Subject))
###############################
```

We also need to remove neutral trials to calculate bin scores. Bin scores are based on comparing one condition to a baseline condition. In this case we want to compare the incongruent condition to the baseline congruent condition. So we need to get rid of neutral conditions.

```{r}
## Calculate Binned scores ####
data_binned <- data_trim %>%
  filter(!is.na(RT), !(Subject %in% data_remove$Subject), Condition != "neutral")
###############################
```

And finally calculate bin scores using `bin_score()` from the `englelab` package.

```{r}
## Calculate Binned scores ####
data_binned <- data_trim %>%
  filter(!is.na(RT), !(Subject %in% data_remove$Subject), Condition != "neutral") %>%
  bin_score(rt.col = "RT", accuracy.col = "Accuracy", type = "mean",
            condition.col = "Condition", baseline.condition = "congruent", id = "Subject") %>%
  rename(FlankerBin = "BinScore")
###############################
```

Awesome! Now we have two dataframes, one, `data_flanker`, with FlankerEffect scores and another, `data_binned` with FlankerBin scores. They both have one row per subject. Now we can merge these two dataframes together using the `merge()` function from base R.

```{r eval = FALSE}
## Merge dataframes and save ####
data_flanker <- merge(data_flanker, data_binned, by = "Subject", all = TRUE)
#################################
```

### Save data file

And finally save the datafile

```{r}
## Merge dataframes and save ####
data_flanker <- merge(data_flanker, data_binned, by = "Subject", all = TRUE)
write_delim(data_flanker, path = here(output.dir, output.file), delim = "\t", na = "")
#################################
```

If we put it all together your R script should look something like:

```{r eval = FALSE}
## Setup ####
library(here)
library(readr)
library(dplyr)
library(datawrangling)
library(englelab)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- directories$raw
output.dir <- directories$scored

## Set import and output files
import.file <- "Flanker_raw.txt"
output.file <- "Flanker_Scores.txt"
#############

## Import ####
import <- read_delim(here(import.dir, "Flanker_raw.txt"), "\t", escape_double = FALSE, trim_ws = TRUE)
##############

## Trim RTs ####
data_trim <- import %>%
  filter(TrialProc == "real") %>%
  mutate(RT = ifelse(RT < 200, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = 3.5, replace = "cutoff") %>%
  ungroup()
#################

## Calculate FlankerEffect on RT and Accuracy ####
data_flanker <- data_trim %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  summarise(RT.mean = mean(RT, na.rm = TRUE),
            Accuracy.mean = mean(Accuracy, na.rm = TRUE)) %>%
  ungroup() %>%
  reshape_spread(variables = "Condition", values = c("RT.mean", "Accuracy.mean"), id = "Subject") %>%
  mutate(FlankerEffect_RT = incongruent_RT.mean - congruent_RT.mean,
         FlankerEffect_ACC = incongruent_Accuracy.mean - congruent_Accuracy.mean)
##################################################

## Remove poor performing subjects ####
data_remove <- data_flanker %>%
  center(variables = c("congruent_Accuracy.mean", 
                       "incongruent_Accuracy.mean", 
                       "neutral_Accuracy.mean"), 
         standardize = TRUE) %>%
  filter(congruent_Accuracy.mean_z < (-3.5) |
           incongruent_Accuracy.mean_z < (-3.5) | 
           neutral_Accuracy.mean_z < (-3.5))

data_flanker <- remove_save(data_flanker, data_remove, 
                            output.dir = here(output.dir, "removed"), 
                            output.file = "Flanker_removed.txt")
#######################################

## Calculate Binned scores ####
data_binned <- data_trim %>%
  filter(!is.na(RT), !(Subject %in% data_remove$Subject), Condition != "neutral") %>%
  bin_score(rt.col = "RT", accuracy.col = "Accuracy", type = "mean",
            condition.col = "Condition", baseline.condition = "congruent", id = "Subject") %>%
  rename(FlankerBin = "BinScore")
###############################

## Merge dataframes and save ####
data_flanker <- merge(data_flanker, data_binned, by = "Subject", all = TRUE)
write_delim(data_flanker, path = here(output.dir, output.file), delim = "\t", na = "")
#################################

rm(list=ls())
```

You can see that with the way the script is written it is not immediately obvious what data cleaning criteria we decided to use. The values are embedded in the middle of a lot of other code. If we want to make our script more transparent and easier to read we can set the data cleaning criteria as objects at the top of the script in the **Set up** section. This will, at the same time, make it easier to change the criteria if we decide to do so.

We can add the following code to the setup section

```{r}
## Set Trimming criteria
rt.min <- 200
rt.trim <- 3.5
acc.criteria <- -3.5
```

* __rt.min__: The minimum value on RT allowed. Set at 200 ms

* __rt.trim__: RT trimming criteria. Set at 3.5 SDs

* __acc.criteria__: Accuracy performance criteria for removing poor performing subjects. Set at -3.5 SDs

Then we will need to replace the values in the script that correspond to these data cleaning steps.

Doing so results in a final script that looks like:

```{r eval = FALSE}
## Setup ####
library(here)
library(readr)
library(dplyr)
library(datawrangling)
library(englelab)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- directories$raw
output.dir <- directories$scored

## Set import and output files
import.file <- "Flanker_raw.txt"
output.file <- "Flanker_Scores.txt"

## Set Trimming criteria
rt.min <- 200
rt.trim <- 3.5
acc.criteria <- -3.5
#############

## Import ####
import <- read_delim(here(import.dir, "Flanker_raw.txt"), "\t", escape_double = FALSE, trim_ws = TRUE)
##############

## Trim RTs ####
data_trim <- import %>%
  filter(TrialProc == "real") %>%
  mutate(RT = ifelse(RT < rt.min, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = rt.trim, replace = "cutoff") %>%
  ungroup()
#################

## Calculate FlankerEffect on RT and Accuracy ####
data_flanker <- data_trim %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  summarise(RT.mean = mean(RT, na.rm = TRUE),
            Accuracy.mean = mean(Accuracy, na.rm = TRUE)) %>%
  ungroup() %>%
  reshape_spread(variables = "Condition", values = c("RT.mean", "Accuracy.mean"), id = "Subject") %>%
  mutate(FlankerEffect_RT = incongruent_RT.mean - congruent_RT.mean,
         FlankerEffect_ACC = incongruent_Accuracy.mean - congruent_Accuracy.mean)
##################################################

## Remove poor performing subjects ####
data_remove <- data_flanker %>%
  center(variables = c("congruent_Accuracy.mean", 
                       "incongruent_Accuracy.mean", 
                       "neutral_Accuracy.mean"), 
         standardize = TRUE) %>%
  filter(congruent_Accuracy.mean_z < (acc.criteria) |
           incongruent_Accuracy.mean_z < (acc.criteria) | 
           neutral_Accuracy.mean_z < (acc.criteria))

data_flanker <- remove_save(data_flanker, data_remove, 
                            output.dir = here(output.dir, "removed"), 
                            output.file = "Flanker_removed.txt")
#######################################

## Calculate Binned scores ####
data_binned <- data_trim %>%
  filter(!is.na(RT), !(Subject %in% data_remove$Subject), Condition != "neutral") %>%
  bin_score(rt.col = "RT", accuracy.col = "Accuracy", type = "mean",
            condition.col = "Condition", baseline.condition = "congruent", id = "Subject") %>%
  rename(FlankerBin = "BinScore")
###############################

## Merge dataframes and save ####
data_flanker <- merge(data_flanker, data_binned, by = "Subject", all = TRUE)
write_delim(data_flanker, path = here(output.dir, output.file), delim = "\t", na = "")
#################################

rm(list=ls())
```

## `source()` in Masterscript

Now we can add lines of code in the manuscript to execute or `source()` the two scripts, "1_flanker_raw.R" and "2_flanker_score.R".

```{r eval=FALSE}
## Setup ####
library(here)

## Set the directory tree
directories <- list(scripts = "R Scripts",
                    data = "Data Files",
                    raw = "Data Files/Raw Data",
                    messy = "Data Files/Raw Data/E-Merge",
                    scored = "Data Files/Scored Data",
                    results = "Results")

saveRDS(directories, here("directories.rds"))
#############

## "messy" to "tidy" raw data
source(here("R Scripts", "1_flanker_raw.R"), echo=TRUE)

## "tidy" to scored data
source(here("R Scripts", "2_flanker_score.R"), echo=TRUE)

rm(list=ls())
```

In using the mastersript you can either execute the entire script by clicking on "Source" or you can run one line of code at a time. For instance, maybe you have already created the "tidy" raw data files. You can open up the masterscript and simply execute the line of code that sources the script to score the task data. This gives you flexibility in controlling your scripts. This becomes more useful when you have a lot of scripts to run (we only have two in this case so it is not too big of a deal). 

********

```{r echo=FALSE, message=FALSE, warning=FALSE}
rm(list=ls())
```

********

**Now onto the really fun stuff, data visualization and statistical analysis!**

