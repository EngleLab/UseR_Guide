# Example: Data Preparation

```{r echo=FALSE}
knitr::include_graphics(rep("images/workflow.png"))
```

Chapters 4 through 6 should have provided you all you need to know in order to start writing scripts to get your data ready for statistical analysis. The data preparation steps include **1)** converting "messy" raw data to "tidy" raw data and **2)** creating data file with task scores that have gone through data cleaning.

Based on the information from Chapters 4 through 6. **This Chapter** will go over step-by-step how to create R scripts to do data preparation using an example data set from the Flanker task. 

********

## Initial Setup

### Set up directory structure

First let's setup our directory organization. In the directory where your .Rproj file is located, you should create the following folders:

* __R Scripts__ - A folder to put all your scripts in one place

* __Data Files__ - A folder where any data files will be stored

* __Results__ - A folder where any outputed results and figures will be stored

When conducting a study you might have other directores such as "Tasks" where the task files are located, or "Methods" where any methods documents or materials are located.

The **Results** directory will become relevant later when we get into performing statistical analyses on data.

Within the **Data Files** directory you should create the following folders:

* __Raw Data__ - A folder containing raw data files

* __Scored Data__ - A folder containig scored data files

Within the **Raw Data** folder you should create the following directory

* __E-Merge__ - A folder containing E-Merged and exported .txt merged files

This structure helps to keep clear where we are importing and outputing data files to in the data workflow process.

* The "messy" raw data files are located in the **E-Merge** folder.

* The "tidy" raw data files are located in the **Raw Data** folder.

* The scored task files are located in the **Scored Data** folder.

Our R Scripts should be able to completely (100%) recreate ALL files in the **Raw Data** and **Scored Data** files based on what is in the **E-Merge** folder. 

## Masterscript

In Chapter 6, you saw an example masterscript. Lets' go over how to begin creating one.

First open a new script window **File -> New File -> R Script**

Save the script as "masterscript_RTutorial.R" to where your .Rproj file is located (the home directory).

Alternatively you might prefer to save the script as "0_masterscript_RTutorial.R" in the **R Scripts** folder. The reason for the 0 will become evident later.

At the top of every script I like to have a "Setup" section where I load packages, set import and output directories, and set any other important variables.

In the masterscript I like to create a list object that contains the directory structure we created above. And then save that directory tree as an R object (.rds) to the home directory. 

What this allows is for each script that we are going to create to access the same directory tree by importing the directory tree R object file (.rds). It will not be apparent to you now, but this will save a lot of time when you have many R scripts. 

For instance: If the folder names have changed, you will not have to update the file paths in each R script, rather you can just do it from the masterscript. Also, if you want to copy and paste the same scripts to use in a different study (that used the same tasks) then, again, you do not have to update each R script to reflect the different folder names for that study. You can just update the masterscript.

This allows you to foucs on writing and executing the scripts rather than wasting time on getting the file path names perfect across every script.

```{r collapse=TRUE, message=FALSE}
## Setup ####
library(here)

## Set the directory tree
directories <- list(scripts = "R Scripts",
                    data = "Data Files",
                    raw = "Data Files/Raw Data",
                    messy = "Data Files/Raw Data/E-Merge",
                    scored = "Data Files/Scored Data",
                    results = "Results")

saveRDS(directories, here("directories.rds"))
#############
```

Now if we want to access the **E-Merge** folder path in an R Script we could do so by

```{r collapse=TRUE}
directories <- readRDS(here("directories.rds"))

directories$messy
```

For now we are done with the masterscript. We will come back later and add lines of code to run the scripts you will create in these examples.

Go ahead and source the masterscript to create the directories object file.

********

<br><br>

********

## Creating "messy" Merged File

### Flanker Data Set

For this tutorial we will use an example data set from the Arrow Flanker task.

You can download this example data set here 

[Download Example Flanker Data](http://englelab.gatech.edu/R/example_data/Flanker_Example.zip)

Unzip the file to the **E-Merge** folder.

One of the files is an E-Merged file, the other is the E-Merged file exported to a tab-delimited .txt file. There is also a folder labled **subj**. 

Before we can begin the data preparation procedures, we need to create a "messy" raw data file that is a merge of the individual subject files. 

Typically, when you are doing a study there are a couple of steps you need to do in order to create this file.

1. You need to create an E-Merged file using the E-Merge software. 

2. You need to export that E-Merged file to a .txt file. 

I've already done these two steps for you. 

Altenratively, in E-Prime 3.0 we will have the option to skip over these two steps completely. In E-Prime 3.0 there is the option to output a .txt version of the .edat file that is created when a subject finishes a task. This means we will be able to directly import the individual subject data files into R without going through E-Prime software. 

#### Skipping E-Merge with E-Prime 3.0

The **subj** folder, in the zip folder you downloaded, contains individual subject .edat files exported as a .txt file. We will cover how to merge these individual files into one Merged file (which has typically been done through E-Merge software).

Create a new script and save it as "._study_finish.txt" in the **R Scripts** folder. The purpose of this script is to get to a single Merged file for all subject. This is a step that is typically only done once or as few times as possible. Because of this will not put it into the masterscript and we do not assign the script name a number (use "." in place).

First create the setup section at the top of the script. We will need the following packages; `here`, `datawrangling`, and `readr`.

```{r message=FALSE, warning=FALSE}
## Setup ####
library(here)
library(datawrangling)
library(readr)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- paste(directories$messy, "subj", sep = "/")
output.dir <- directories$messy
#############
```

We will use the `files.bind()` function from the `datawrangling` package to stack each subject file ontop of one another.

```{r collapse = TRUE, message = FALSE, warning = FALSE, eval = FALSE}
## Merge data files
files.bind(path = here(import.dir), pattern = "Flanker", output.file = here(output.dir, "Flanker.txt"))
```

This should do it. So your entire script should look something like

```{r message=FALSE, warning=FALSE, collapse = TRUE, eval = FALSE}
## Setup ####
library(here)
library(datawrangling)
library(readr)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- paste(directories$messy, "subj", sep = "/")
output.dir <- directories$messy
#############

## Merge data files
files.bind(path = here(import.dir), pattern = "Flanker", output.file = here(output.dir, "Flanker.txt"))

rm(list=ls())
```

Source and save your script.

********

<br><br>

********

## "messy" to "tidy"

The next step in the data preparation procedure is to creat a "tidy" raw data file from the "messy" raw data file.

### What to Include

Creating a "tidy" raw data file is essentialy a process of elimination. Getting rid of columns and rows that have no value. You may also want to rename columns and values.

So what should you keep? 

You want to keep all columns that are essential to the design of the task. This might include a column that specifies the condition for each trial, a column that specifies a feature of the target stimulus, performance variables, and more. 

As for rows, I suggest keeping both practice and real trials. It is easy to filter out practice trials later. The "tidy" raw data file should contain only one row per trial per subject. 

You should probably rename variables and values to be easy for those unfamiliar with how the task was programmed to understand. Also if you have similar tasks (_Flanker_ and _Stroop_) it is probably a good idea to give similar names to variables and values. For instance, give the same name to the column that contains the condition type. Also use the same value names for each condition (not _congruent_ for one task, and _cong_ for another). Use a standard name for columns with reaction time and accuracy values (RT, Accuracy).

### Import "messy" data

Open a new script file and save it to the **R Scripts** folder as "1_flanker_raw"

The "1" denotes that this is the first step in our workflow process; converting "messy" raw data files to "tidy" raw data files.

Again, create the setup section at the top

```{r message = FALSE, warning = FALSE}
## Setup ####
library(here)
library(readr)
library(dplyr)
library(datawrangling)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- directories$messy
output.dir <- directories$raw
#############
```

Okay, first thing is to import the "messy" merged .txt data file. To do this use the `read_delim` function from the `readr` package. 

```{r collapse=TRUE, warning=FALSE, message=FALSE}
## Import
import <- read_delim(here(import.dir, "Flanker.txt"), "\t", escape_double = FALSE, trim_ws = TRUE)
```

You can then view the data file with

```{r eval=FALSE}
View(import)
```

It is a mess, right? Here are some things you need to know about the "messy" raw data file. These are the columns and what type of values they contain:

********

**Subject**: Subject number

**Procedure[Trial]**: Procedure type (keep: TrialProc and PracTrialProc)

**PracTrialList.Sample**: Trial number for practice trials

**TrialList.Sample**: Trial number for real trials

**FlankerType**: condition for real and practice trials (Values are: congruent, incongruent, and neutral)

**PracSlideTarget.RT**: Reaction time for practice trials

**PracSlideTarget.ACC**: Accuracy for practice trials

**PracSlideTarget.RESP**: Response for practice trials ({LEFTARROW} = left and {RIGHTARROW} = right)

**SlideTarget.RT**: Reaction time for real trials

**SlideTarget.ACC**: Accuracy for real trials

**SlideTarget.RESP**: Response for real trials ({LEFTARROW} = left and {RIGHTARROW} = right)

**TargerDirection**: direction of the target arrow for practice trials

**TargetDirection**: direction of the target arrow for real trials

**SessionDate**: Date of session

**SessionTime**: Time of session

********

### Remove Duplicate Subjects

Now it happens on occasion that the wrong subject number is entered in when an RA is starting up a task. This can result in duplicate Subject numbers in the E-Merge file. Luckily I have created a function to remove the duplicate subjects, and put their information (with session date and time) into a specific file. This file will be created in a new folder called "duplicates".

The function is `duplicates.remove()` from the `datawrangling` package on my GitHub.

It can be difficult to remember what arguments you need to include in a function. To see helpful documentation about a function you can type in the console

```{r eval=FALSE}
library(datawrangling)
?duplicates.remove
```


```{r warning=FALSE, collapse=TRUE, message=FALSE}
## Import
import <- read_delim(here(import.dir, "Flanker.txt"), "\t", escape_double = FALSE, trim_ws = TRUE)
import <- duplicates.remove(import, taskname = "Flanker", output.folder = here(output.dir))
```

### Filter

Filter only relevant rows. We want to keep only the rows that contain trials from the practice and real trials. To do this we use the `filter()` function of the `dplyr` package. 

```{r warning=FALSE, collapse=TRUE, message=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc")
```

The column names are contained in single quotes because the names contain the special characters `[ ]`. There are certain characters R does not like to use as variable names and one of them is square brackets.

### Rename

Now the column specifying real vs practice trials is a little tedious to keep typing out since it requires the single quotes and brackets. We will also want to rename this column to be more coherent in the final "tidy" data format anyways. To rename columns we can use `rename()` function in `dplyr`.

```{r warning=FALSE, collapse=TRUE, message=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`)
```

### Mutate

Let's change the values in `TrialProc`. Right now real trials have the value of "TrialProc". The same name as the column, not good! And the "practice" trials have the value of "PractTrialProc". Let's simply change these values to "real" and "practice", respectively. 

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = ifelse(TrialProc=="TrialProc", "real", "practice"))
```

Note that we are not being very specific with `ifelse()`. Rows that do not equal `"TrialProc"` get set as `"practice"`. This is okay ONLY because we already applied a filter to only include rows with the value `"TrialProc"` or with the value `"PracTrialProc"`. If we did not apply this filter, or if there were more than two values for the column `TrialProc`, then rows that were not `"PracTrialProc"` would get set to `"practice"` as well. 

The point is, be careful how you are using `ifelse()`.

An alternative to `ifelse()` that I like is the `case_when()` function from `dplyr`. You can be more specific with `case_when()`. 

```{r collapse = TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)))
```

In `case_when()` you still specify a logical argument `TrialProc=="TrialProc"` and you set what should happen when that argument is TRUE by using the `~` symbol. So, cases when `TrialProc=="TrialProc"` set `~` value to `"real"`. At the End of `case_when()` you need to specify what should happen if none of those cases specified above are TRUE. You do this by typing `TRUE ~ ` followed by what to do. Usually you will want to set the value to missing. The tricky thing here is that `NA` is a logical value. A column of values can only be of one type (e.g. a column cannot contain both logical and character values). To get around this we just set `NA` to whatever value the column should take `as.character(NA)`.

********

Okay now let's move on to figuring out what other columns we want to keep and if we need to do any more computations on them.

We want to keep the columns that specify the following information

* Subject number
* TrialProc (real vs practice)
* Trial number 
* Condition (congruent vs incongruent)
* Reaction time
* Accuracy
* Response
* Target arrow direction (left or right)
* Session Date
* Session Time

This gets a little more tricky here because the information for some of these variables are in one column for practice trials and a different column for real trials. That means we need to merge the information from these two columns into one. We can do this using the`mutate()` function from the `dplyr` package.

For instance the RT data for practice trials is contained in the column `PracSlideTarget.RT` and for real trials RT data is in `SlideTarget.RT`.

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT))
```

So the new column RT gets set to the value that is contained in SlideTarget.RT if it is a real trial, if not then the RT gets a value contained in PracSlideTarget.RT

We can do the same thing for trial, accuracy, response, and target arrow direction. Combining them all into one `mutate()` function

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT),
         Accuracy = ifelse(TrialProc=="real", SlideTarget.ACC, PracSlideTarget.ACC),
         TargetArrowDirection = ifelse(TrialProc=="real", TargetDirection, TargerDirection),
         Response = ifelse(TrialProc=="real", SlideTarget.RESP, PracSlideTarget.RESP))
```

You might want to change the values in the Response and CorrectResponse columns to be more clear (left and right).

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT),
         Accuracy = ifelse(TrialProc=="real", SlideTarget.ACC, PracSlideTarget.ACC),
         TargetArrowDirection = ifelse(TrialProc=="real", TargetDirection, TargerDirection),
         Response = ifelse(TrialProc=="real", SlideTarget.RESP, PracSlideTarget.RESP),
         Response = ifelse(Response=="{LEFTARROW}", "left", ifelse(Response=="{RIGHTARROW}", "right", NA)))
```

Notice how I included an `ifelse()` function inside of an `ifelse()` function. The inner `ifelse()` will occur if `Response` does not equal `"{LEFTARROW}"`. This is another way to be more specific when using `ifelse()` instead of `case_when()`. It is up to you which you prefer to use.

You have to be careful with `ifelse()` statements because sometimes it does something you do not expect it to. **That is why it is always important to check to make sure your code is performing as you want it to.** View the dataframe to make sure everything is good. The new columns will be added at the end of the dataframe.

### Select

We are getting closer to a "tidy" raw data file. The only thing left is to select the columns we want to keep. We do this by using the `select()` function from the `dplyr` package.

Remember we want to only select columns with the following information

* Subject number
* Trial number 
* Condition
* Reaction time
* Accuracy
* Response
* Correct Response
* Target arrow direction
* Session Date
* Session Time

```{r collapse=TRUE, message=FALSE, warning=FALSE}
## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT),
         Accuracy = ifelse(TrialProc=="real", SlideTarget.ACC, PracSlideTarget.ACC),
         TargetArrowDirection = ifelse(TrialProc=="real", TargetDirection, TargerDirection),
         Response = ifelse(TrialProc=="real", SlideTarget.RESP, PracSlideTarget.RESP),
         Response = ifelse(Response=="{LEFTARROW}", "left", ifelse(Response=="{RIGHTARROW}", "right", NA))) %>%
  select(Subject, TrialProc, Trial, Condition = FlankerType, RT, Accuracy, Response, TargetArrowDirection, SessionDate, SessionTime)
```

### Save to File

The function of an R script is to import a dataframe -> transform or analyze the dataframe -> output a final product (a new dataframe or analysis output). The objects which an R script creates (which you can see in the **Environemnt** window) are not the final end point. These are just temporary objects that are used to go from an input -> output. 

You have done the importing and transforming; now you need to output the final product - which is a saved .txt file of the "tidy" raw data.

To save the dataframe to a .txt file you will use the `write_delim()` function of the `readr` package.

```{r collapse=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
## Save
write_delim(data_flanker, path = here(output.dir, "Flanker_raw.txt"), delim = "\t", na = "")
```

********

Then if we were to put it all together, using the template from the previous chapter:

```{r message = FALSE, warning = FALSE, collapse=TRUE}
## Setup ####
library(here)
library(readr)
library(dplyr)
library(datawrangling)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- directories$messy
output.dir <- directories$raw
#############

## Import
import <- read_delim(here(import.dir, "Flanker.txt"), "\t", escape_double = FALSE, trim_ws = TRUE) %>%
  duplicates.remove(taskname = "Flanker", output.folder = here(output.dir))

## Tidy
data_flanker <- import %>%
  filter(`Procedure[Trial]`=="TrialProc" | `Procedure[Trial]`=="PracTrialProc") %>%
  rename(TrialProc = `Procedure[Trial]`) %>%
  mutate(TrialProc = case_when(TrialProc=="TrialProc" ~ "real",
                               TrialProc=="PracTrialProc" ~ "practice",
                               TRUE ~ as.character(NA)),
         RT = ifelse(TrialProc=="real", SlideTarget.RT, PracSlideTarget.RT),
         Accuracy = ifelse(TrialProc=="real", SlideTarget.ACC, PracSlideTarget.ACC),
         TargetArrowDirection = ifelse(TrialProc=="real", TargetDirection, TargerDirection),
         Response = ifelse(TrialProc=="real", SlideTarget.RESP, PracSlideTarget.RESP),
         Response = ifelse(Response=="{LEFTARROW}", "left", ifelse(Response=="{RIGHTARROW}", "right", NA))) %>%
  select(Subject, TrialProc, Trial, Condition = FlankerType, RT, Accuracy, Response, TargetArrowDirection, SessionDate, SessionTime)

## Save
write_delim(data_flanker, path = here(output.dir, "Flanker_raw.txt"), delim = "\t", na = "")

rm(list=ls())
```

********

<br>

********

## "tidy" raw to scored

Great! You have written an R script for the first step in Data Preparation, converting a "messy" raw data file to a "tidy" raw data file. 

Next we will go over how to write an R script for the second step - which involves data cleaning and task scoring.

This step is more complicated and often times requires some forethought. But we don't always have the best forethought so you will likely re-write previous lines of code.

One thing you must think about before writing the script for this stage is the statistical analyses you eventually plan on conducting. This is because the final resulting dataframe will depend on what analyses you do. The data structure required for conducting a between-subject mean comparison (t-tests or ANOVA) will be different from the data structure required for a regression. The type of statistical analyses you plan on conducting will determine the final dataframe you want to end up at in this stage of data preparation.

Another thing you must think about before hand are the final dependent variables (or task scores) you want to calaculate. For instance, in the Flanker task there are several task scores we might want to calculate (in a regression context). 

* __FlankerEffect on RT__: Mean reaction time difference between incongruent and congruent trials

* __FlankerEffect on Accuracy__: Mean accuracy difference between incongruent and congruent trials

* __Flanker Binned Scores__: A scoring method to combine accuracy and reaction time (an alternative to difference scores)

Finally, you should also think about what sort of data cleaning procedures you want to use. For instance, maybe you only want to calculate the FlankerEffect on RT for accurate trials and not innaccurate trials. Or perhaps you want to remove trials that are less than 200ms (too fast of responding to reflect cognitive processing).

In the example we are about to go through we will implement the following data cleaning procedures when calculating the three scores listed above. They will be implemented in the following order

1. Remove trials with less than 200ms reaction time

2. In order to calculate FlankerEffect on RT for accurate trials, - Set RT on innacurate trials to missing `NA`.

3. Trim RTs. Replace Outlier RTs that are above or below **3.5 SDs** of the mean, with values exactly at **3.5 SDs** above or below the mean. This is evaluated for each Subject by each condition seprately.

4. Finally remove subjects that on any Trial condition (congruent, incongruent, neutral) performed less than **3.5 standard deviations** below the mean on that condition.

********

First start by opening a new script file and saving it to the **R Scripts** folder as "2_flanker_score"

### Set up

Create the Setup section of the R script. In addition to the import and output directories we will set the data cleaning paramters as well.

```{r}
## Setup ####
library(here)
library(readr)
library(dplyr)
library(datawrangling)
library(englelab)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- directories$raw
output.dir <- directories$scored

## Set data cleaning parameters
min_RT.criteria <- 200
sd.criteria <- 3.5
#############
```

Import directory is the **Raw Data** folder where the "tidy" raw file is located. The output directory is the **Scored Data** folder. `min_RT.criteria` for data cleaning procedure **1** above. `sd.criteria` for data cleaning procedures **3** and **4**

### Import

```{r message = FALSE}
## Import
import <- read_delim(here(import.dir, "Flanker_raw.txt"), "\t", escape_double = FALSE, trim_ws = TRUE)
```

### Calculate FlankerEffect on RT and Accuracy

The general strategy we will take is to create two different dataframes. 1) `data_flanker` in which we calculate the FlankerEffect on RT and Accuracy and 2) `data_binned` in which we calculate the Flanker Binned scores.

In calculating the FlankerEffect, we first need to do some data cleaning

#### Data Cleaning

1. First we we should remove too fast of RTs

```{r}
## Calculate FlankerEffect on RT and Accuracy
data_flanker <- import %>%
  filter(RT >= min_RT.criteria)
```

2. Then set RTs to `NA` on innacurate trials

```{r}
## Calculate FlankerEffect on RT and Accuracy
data_flanker <- import %>%
  filter(RT >= min_RT.criteria) %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT))
```

3. Trim RTs individual per subject per condition. To do this we will use the `group_by()` (from Chapter 4) and `trim()` (from Chapter 6) functions

```{r}
## Calculate FlankerEffect on RT and Accuracy
data_flanker <- import %>%
  filter(RT >= min_RT.criteria) %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff")
```

Note the `replace` argument in `trim()`. Outliers are being replaced with the value at 3.5 SDs of the mean (the cutoff value). Outliers can also be replaced with the `"mean"`, `"median"`, or `"NA"`.

#### Calculate Mean RTs and Mean Accuracy

Before removing subjects with too low accuracy for each condition we need to calculate mean Accuracy for each condition.

```{r}
## Calculate FlankerEffect on RT and Accuracy
data_flanker <- import %>%
  filter(RT >= min_RT.criteria) %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff") %>%
  summarise(RT.mean = mean(RT, na.rm = TRUE),
            Accuracy.mean = mean(Accuracy, na.rm = TRUE)) %>%
  ungroup()
```

Be sure to `ungroup()` when you are done with it!

And then spread "RT" and "Accuracy" across conditions. Creating columns for mean RT and mean Accuracy for each separate condition.

```{r}
## Calculate FlankerEffect on RT and Accuracy
data_flanker <- import %>%
  filter(RT >= min_RT.criteria) %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff") %>%
  summarise(RT.mean = mean(RT, na.rm = TRUE),
            Accuracy.mean = mean(Accuracy, na.rm = TRUE)) %>%
  ungroup() %>%
  reshape.spread(variables = "Condition", values = c("RT.mean", "Accuracy.mean"), id = "Subject")
```

And we might as well calaculate the FlankerEffects

```{r}
## Calculate FlankerEffect on RT and Accuracy
data_flanker <- import %>%
  filter(RT >= min_RT.criteria) %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff") %>%
  summarise(RT.mean = mean(RT, na.rm = TRUE),
            Accuracy.mean = mean(Accuracy, na.rm = TRUE)) %>%
  ungroup() %>%
  reshape.spread(variables = "Condition", values = c("RT.mean", "Accuracy.mean"), id = "Subject") %>%
  mutate(FlankerEffect_RT = incongruent_RT.mean - congruent_RT.mean,
         FlankerEffect_ACC = incongruent_Accuracy.mean - congruent_Accuracy.mean)
```

#### Remove poor performing subjects

The approach I like to take with entirely removing subjects is to keep a record of those subjects in a data file somewhere. To do this we will create a new dataframe of subjects that will be removed. We will then use a function I created, `remove.save()` from the `datawrangling` package. This function is a short hand way of doing two things at one. 

1. Removing the subjects from the full data file

2. Saving the removed subjects to a specified directory.

The criteria we are removing subjects based on are those who performed 3.5 SDs below the mean. So we first need to calaculate a column of z-scores (on SD units), then filter those who are below 3.5 z-scores.

```{r}
## Remove poor performing subjects
data_remove <- data_flanker %>%
  center(variables = c("congruent_Accuracy.mean", 
                       "incongruent_Accuracy.mean", 
                       "neutral_Accuracy.mean"), 
         standardize = TRUE) %>%
  filter(congruent_Accuracy.mean_z > sd.criteria | congruent_Accuracy.mean_z < (-1*sd.criteria) |
           incongruent_Accuracy.mean_z > sd.criteria | incongruent_Accuracy.mean_z < (-1*sd.criteria) | 
           neutral_Accuracy.mean_z > sd.criteria | neutral_Accuracy.mean_z < (-1*sd.criteria))
```

Then use `remove.save()`

```{r}
data_flanker <- remove.save(data_flanker, data_remove, 
                            output.dir = here(output.dir, "removed"), 
                            output.file = "Flanker_removed.txt")
```

The first argument is the full data frame (`data_flanker`) and the second argument is the dataframe that contains the subjects to be removed (`data_remove`). You should now see a folder called **removed** in the **Scored Data** folder with a file called "Flanker_removed.txt".

### Calculate Binned Scores

Great! We have now calculated FlankerEffects scores and perfomred the data cleaning procedures. Now we need to calculate Binned scores. The `data_flanker` dataframe is no longer in a formate that we can calculate bin scores. We need to the original import dataframe that has trial level data. 

First, We should do the same RT data cleaning procedures as we did for calculating FlankerEffect on RT. Let's call this new dataframe `data_binned`.

```{r}
## Calculate Binned scores
data_binned <- import %>%
  filter(RT >= min_RT.criteria) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff") %>%
  ungroup()
```

We should also remove the poor performing subjects. This step is actually really important for the binning procedure because bin scores are relative to other subjects in the data.

```{r}
## Calculate Binned scores
data_binned <- import %>%
  filter(RT >= min_RT.criteria) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff") %>%
  ungroup() %>%
  filter(!(Subject %in% data_remove$Subject))
```

We also need to remove neutral trials to calculate bin scores. Bin scores are based on comparing one condition to a baseline condition. In this case we want to compare the incongruent condition to the baseline congruent condition. So we need to get rid of neutral conditions.

```{r}
## Calculate Binned scores
data_binned <- import %>%
  filter(RT >= min_RT.criteria) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff") %>%
  ungroup() %>%
  filter(!(Subject %in% data_remove$Subject), Condition != "neutral")
```

And finally calculate bin scores using `bin.score()` from the `englelab` package.

```{r}
## Calculate Binned scores
data_binned <- import %>%
  filter(RT >= min_RT.criteria) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff") %>%
  ungroup() %>%
  filter(!(Subject %in% data_remove$Subject), Condition != "neutral") %>%
  bin.score(rt.col = "RT", accuracy.col = "Accuracy", type = "mean",
            condition.col = "Condition", baseline.condition = "congruent", id = "Subject") %>%
  rename(FlankerBin = "BinScore")
```

Awesome! Now we have two dataframes, one, `data_flanker`, with FlankerEffect scores and another, `data_binned` with FlankerBin scores. They both have one row per subject. Now we can merge these two dataframes together using the `merge()` function from base R.

```{r}
## Merge dataframes
data_flanker <- merge(data_flanker, data_binned, by = "Subject", all = TRUE)
```

### Save data file

And finally save the datafile

```{r}
## Save data
write_delim(data_flanker, path = here(output.dir, "Flanker_Scores.txt"), delim = "\t", na = "")

rm(list=ls())
```

If we put it all together your R script should look something like:

```{r eval = FALSE}
## Setup ####
library(here)
library(readr)
library(dplyr)
library(datawrangling)
library(englelab)

## Set import and output directories
directories <- readRDS(here("directories.rds"))
import.dir <- directories$raw
output.dir <- directories$scored

## Set data cleaning parameters
min_RT.criteria <- 200
sd.criteria <- 3.5
#############

## Import
import <- read_delim(here(import.dir, "Flanker_raw.txt"), "\t", escape_double = FALSE, trim_ws = TRUE)

## Calculate FlankerEffect on RT and Accuracy
data_flanker <- import %>%
  filter(RT >= min_RT.criteria) %>%
  mutate(RT = ifelse(Accuracy==0, NA, RT)) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff") %>%
  summarise(RT.mean = mean(RT, na.rm = TRUE),
            Accuracy.mean = mean(Accuracy, na.rm = TRUE)) %>%
  ungroup() %>%
  reshape.spread(variables = "Condition", values = c("RT.mean", "Accuracy.mean"), id = "Subject") %>%
  mutate(FlankerEffect_RT = incongruent_RT.mean - congruent_RT.mean,
         FlankerEffect_ACC = incongruent_Accuracy.mean - congruent_Accuracy.mean)

## Remove poor performing subjects
data_remove <- data_flanker %>%
  center(variables = c("congruent_Accuracy.mean", 
                       "incongruent_Accuracy.mean", 
                       "neutral_Accuracy.mean"), 
         standardize = TRUE) %>%
  filter(congruent_Accuracy.mean_z > sd.criteria | congruent_Accuracy.mean_z < (-1*sd.criteria) |
           incongruent_Accuracy.mean_z > sd.criteria | incongruent_Accuracy.mean_z < (-1*sd.criteria) | 
           neutral_Accuracy.mean_z > sd.criteria | neutral_Accuracy.mean_z < (-1*sd.criteria))

data_flanker <- remove.save(data_flanker, data_remove, 
                            output.dir = here(output.dir, "removed"), 
                            output.file = "Flanker_removed.txt")

## Calculate Binned scores
data_binned <- import %>%
  filter(RT >= min_RT.criteria) %>%
  group_by(Subject, Condition) %>%
  trim(variables = "RT", cutoff = sd.criteria, replace = "cutoff") %>%
  ungroup() %>%
  filter(!(Subject %in% data_remove$Subject), Condition != "neutral") %>%
  bin.score(rt.col = "RT", accuracy.col = "Accuracy", type = "mean",
            condition.col = "Condition", baseline.condition = "congruent", id = "Subject") %>%
  rename(FlankerBin = "BinScore")

## Merge dataframes
data_flanker <- merge(data_flanker, data_binned, by = "Subject", all = TRUE)

## Save data
write_delim(data_flanker, path = here(output.dir, "Flanker_Scores.txt"), delim = "\t", na = "")

rm(list=ls())
```


## `source()` in Masterscript

Now we can add lines of code in the manuscript to execute or `source()` the two scripts, "1_flanker_raw.R" and "2_flanker_score.R".

```{r eval=FALSE}
## Setup ####
library(here)

## Set the directory tree
directories <- list(scripts = "R Scripts",
                    data = "Data Files",
                    raw = "Data Files/Raw Data",
                    messy = "Data Files/Raw Data/E-Merge",
                    scored = "Data Files/Scored Data",
                    results = "Results")

saveRDS(directories, here("directories.rds"))
#############

## "messy" to "tidy" raw data
source(here("R Scripts", "1_flanker_raw.R"), echo=TRUE)

## "tidy" to scored data
source(here("R Scripts", "2_flanker_score.R"), echo=TRUE)

rm(list=ls())
```

In using the mastersript you can either execute the entire script by clicking on "Source" or you can run one line of code at a time. For instance, maybe you have already created the "tidy" raw data files. You can open up the masterscript and simply execute the line of code that sources the script to score the task data. This gives you flexibility in controlling your scripts. This becomes more useful when you have a lot of scripts to run (we only have two in this case so it is not too big of a deal). 

********

```{r echo=FALSE, message=FALSE, warning=FALSE}
rm(list=ls())
```

********

**Now on to scoring the "tidy" raw data file**

