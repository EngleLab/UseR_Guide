[
["englelab-packages.html", "Chapter 6 EngleLab Packages 6.1 englelab 6.2 datawrangling 6.3 Binding Individual Subject Files", " Chapter 6 EngleLab Packages I have created R packages that contain functions to more easily score tasks, transform variables, and clean data. In this chapter you will learn about the functions from these two packages englelab https://github.com/EngleLab/englelab datawrangling https://dr-jt.github.io/datawrangling I am hosting these packages on GitHub and can be downloaded using the devtools package install.packages(&quot;devtools&quot;) devtools::install_github(&quot;EngleLab/englelab&quot;) devtools::install_github(&quot;dr-JT/datawrangling&quot;) 6.1 englelab The functions in the englelab package are to create “tidy” raw data files and scored data files from the complex span and fluid intelligence tasks we frequently use. It also contains a function to calculate scores using the binning method from [insert citation here]. There are also functions to calcualte the reliability measures; cronbach’s alpha and split-half reliability. This package is intended to eventually share with other researchers who download the tasks from our website and use R to do data analysis. 6.1.1 “tidy” raw data functions It is suggested to only use the “tidy” raw functions rather than the scoring functions. The reason for this is that the scoring function does not create a “tidy” raw data file - which is useful for doing internal consitency analyses, and is just a good idea to have a “tidy” raw data file for trial-by-trial performance. Here is the list of “tidy” raw data functions: raw.ospan() raw.symspan() raw.rotspan() raw.rapm() raw.numberseries() raw.lettersets() These functions take as input an imported E-Merged or edat file. For the complex span tasks you need to specify the number of blocks administered with the blocks argument. ex. raw.ospan(data, blocks = 2) The output of the raw functions will also contain columns for the subject’s final score on the task. This is why it is suggested to just use the raw functions, you can still easily grab the final score on the task from the outputed file. 6.1.2 Example Here is an example script that uses the raw.ospan() function to import an E-merged data file and output a “tidy” raw data file. ## Set up #### ## Load packages library(readr) library(englelab) ## Set import/output directories import.file &lt;- &quot;data/raw/emerge/ospan.txt&quot; output.file &lt;- &quot;data/raw/ospan_raw.txt&quot; ############## ## Import import &lt;- read_delim(import.file), &quot;\\t&quot;, escape_double = FALSE, trim_ws = TRUE) ## Clean up raw data file and save data_raw &lt;- raw.ospan(import, blocks = 2) ## Save data file write_delim(data_raw, path = output.file, &quot;\\t&quot;, na = &quot;&quot;) 6.1.3 score data functions Again, it is suggested to use the raw functions instead of the score functions. Here is the list of the score functions: score.ospan() score.symspan() score.rotspan() score.rapm() score.numberseries() score.lettersets() Like the raw functions the score functions take as input a “messy” raw E-Merged or edat file. For the complex span tasks you need to specify the number of blocks adminestered. 6.1.4 Calculating Bin Scores The bin.score() function will calculate bin scores. These are the arguments you will need to specify: x: a dataframe with trial level data. Needs to have RT and Accuracy DVs rt.col: Column name in dataframe that contains the reaction time data accuracy.col: Column name in dataframe that contains the accuracy data condition.col: Column name in dataframe that contains the trial condition values baseline.condition: The values that specify the baseline condition (e.g. “congruent”) id: Column name in dataframe that contains the subject identifiers The default argument values are: bin.score(x, rt.col = &quot;RT&quot;, accuracy.col = &quot;Accuracy&quot;, condition.col = &quot;Condition&quot;, baseline.condition = &quot;congruent&quot;, id = &quot;Subject&quot;) Your data file may already be setup with these default value column names. If so, then you just need to specify the dataframe. 6.1.5 Reliability functions cronbach.alpha() This function takes as input a “tidy” raw trial-level dataframe. x: x a dataframe with trial level data trial.col: The column name that identifies trial number value: The column name that identifies the values to be used id: The column name that identifies the Subject IDs. Cronbach’s alpha is calculated using the alpha() function from the psych package. The difficulty in simply using the alpha() function is getting the dataframe in the correct structure. To use alpha() the values that reliability is going to be assessed over need to be in columns. The dataframe, then is one subject per row with a column for each value. For most of our tasks, the values that will be assessed over are the individual Trial level DV (RT or Accuracy). So there needs to be one column for each Trial. This is an unusual data structure and is really only useful for calculating reliability. cronbach.alpha() will save you time by creating the correct data structure for you based on a more common structure that is contained in your “tidy” raw data files (one row per trial per subject, with RT and Accuracy as columns). You should be able to take your “tidy” raw data as input to cronbach.alpha(). The output of cronbach.alpha() is a single value representing Cronbach’s Alpha. splithalf() This function takes as input a “tidy” raw trial-level dataframe. x: x a dataframe with trial level data trial.col: The column name that identifies trial number value: The column name that identifies the values to be used id: The column name that identifies the Subject IDs. The default values are splithalf(data, trial.col = &quot;Trial&quot;, value = NULL, id = &quot;Subject&quot;) The data is split in half by even and odd trials. You should be able to take your “tidy” raw data as input to splithalf(). The output of splithalf() is a single value representing split-half reliability. 6.2 datawrangling It would take too long to cover each of the functions in this package one-by-one. I will cover just a few that are the most commonly used functions. For a descriptions of each function see https://dr-jt.github.io/datawrangling/reference/index.html 6.2.1 Merging Data Files You might find yourself in a situation where you need to merge multiple text files together. There are two types of merge operations that can be performed. In R, a “join” is merging dataframes together that have at least some rows in common (e.g. Same Subject IDs) and have at least one column that is different. The rows that are common serve as the reference for how to “join” the dataframes together. In R, a “bind” is combining datarames together by staking either the rows or columns. It is unlikely that we you will need to do a column bind so we can skip that. A row “bind” takes dataframes that have the same columns but different rows. This will happen if you have separate data files for each subject from the same task. Each subject data file will have their unique rows (subject by trial level data) but they will all have the same columns. The E-Merge software program is performing a row “bind” of each subject .edat file. In E-Prime 2 we have to go through E-Merge to do this process. However, in E-Prime 3.0 there is the option to output an exported .edat file as a tab-delimited .txt file. Using the files.bind() function from the datawrangling package will allow us to skip the E-Merge step. The datawrangling package contains two functions to merge data files together: files.join() files.bind() They both work in a similar way. The files you want to merge need to be in the same folder on your computer. You specify the location of this folder using the path = argument. You need to specify a pattern that uniquely identifies the files you want to merge (e.g. “.txt”, or “Flanker”) using the pattern = argument. Then specify the directory and filename you want to save the merge file to using the output.file = argument. Here are the arguments that can be specified: path: Folder location of files to be merged pattern: Pattern to identify files to be merged delim: Delimiter used in files. Passed onto readr::read_delim() na: How are missing values defined in files to be merged. Passed to readr::write_delim() output.file: File name and path to be saved to. id: Subject ID column name. Passed onto plyr::join_all(by = id). ONLY for files.join() bind: The type of bind to perform (default = “rows”). ONLY for files.bind() 6.2.2 Transformations and Data Cleaning There are a set of function is datawrangling to allow you to more easily transform column values into new variables and to do data cleaning. 6.2.2.1 Create Composites 6.3 Binding Individual Subject Files Now I want to go over how bind individual subject files into one file. The subj folder contains individual files for each subject. You will use these files to learn how to bind multiple subject files into one file. In E-Prime you can use the E-Merge software to bind individual subject .edat2 files, so this is actually not always necessary. However, you may have a task running in a different program othan E-Prime. Also, in E-Prime 3.0 there is the option to save the .edat2 file as a .txt file. This can allow you to bypass using E-Merge and simply create an R script to bind all the .txt files). I have created individual subject files in the subj folder for the sake of this tutorial. You can “bind” either the rows or columns of a dataframe together. A column “bind” means the dataframes have different column (same rows) and you are simply binding the columns together. A row “bind” means the dataframes have different rows (same columns) and you are simply binding the rows of the dataframes ontop of one another. For our purspose here, what we want to do is a row “bind”. Since each subject has the same columns but different rows. We basically want to stack the files ontop of each other. This requires several steps and the use of a for loop. Luckily, I created a function to do this for us so it will be very simple! The function we will use is files.bindr() from my datawrangling package. Remember you can use ?files.bind to see documentation about how to use a function devtools::install_github(&quot;dr-JT/datawrangling&quot;) library(datawrangling) data_merged &lt;- files.bind(path = &quot;data/subj&quot;, pattern = &quot;_Flanker.txt&quot;, delim = &quot;\\t&quot;, na = &quot;&quot;, bind = &quot;rows&quot;, output.file = &quot;data/Flanker_merged.txt&quot;) There are a few arguments you need to specify. path specifies the folder in which all the files are located. pattern is a certain patter of letters that every file has in common. If there are other files in the same folder you want to make sure this pattern is unique to only the files you want to merge. delim specifies both the delimiter that the individual files have and what the final merged file should have. na is how missing values should be specified. bind what type of bind do you wan to perform. “rows” or “columns” or “cols”. output.file is the file path and name to save the merged file to. Here is the function for files.bind(). You can let me know if you have any questions about this. files.bind &lt;- function(path = &quot;&quot;, pattern = &quot;&quot;, delim = &quot;\\t&quot;, na = &quot;&quot;, output.file = &quot;&quot;, bind = &quot;rows&quot;){ filelist &lt;- list.files(path = path, pattern = pattern, full.names = TRUE) import &lt;- list() for (i in seq_along(filelist)){ import[[i]] &lt;- readr::read_delim(filelist[[i]], delim, escape_double = FALSE, trim_ws = TRUE, na = na) } if (bind==&quot;rows&quot;){ bound &lt;- dplyr::bind_rows(import) } if (bind==&quot;columns&quot;|bind==&quot;cols&quot;){ bound &lt;- dplyr::bind_cols(import) } if (output.file!=&quot;&quot;){ readr::write_delim(bound, path = output.file, delim, na = na) } return(bound) } Now on to scoring the “tidy” raw data file "]
]
